{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1v9Csnj2LDxTP4X5ttkOy8aikagPH5TKA",
      "authorship_tag": "ABX9TyPjwL5qsHqs6MWATNMch3Wq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chxbim/FP_ML_TomatoLeafDisease/blob/main/FP_ML_TomatoLeafDisease_Pertanian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm #visualisasi progress bar\n",
        "from sklearn.preprocessing import LabelEncoder #encoder label bt data disk npy\n",
        "#tf keras install + mobileNet\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle #obj serialization"
      ],
      "metadata": {
        "id": "jJwjjUXKAzyD",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#============================================check qty files train/val\n",
        "for cls in os.listdir(val_dir):\n",
        "    cls_path = os.path.join(val_dir, cls)\n",
        "    n_files = len(os.listdir(cls_path))\n",
        "    print(f\"{cls}: {n_files} files\")\n",
        "\n",
        "for cls in os.listdir(train_dir):\n",
        "    cls_path = os.path.join(train_dir, cls)\n",
        "    n_files = len(os.listdir(cls_path))\n",
        "    print(f\"{cls}: {n_files} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "i1ZKLxhStGYT",
        "outputId": "d534903f-ea00-4c68-b431-fd65042959bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2882521213.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#============================================check qty files train/val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcls_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{cls}: {n_files} files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#============================================std img ratio\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "#============================================load pretrained model (extractor)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "def extract_feature(img_path):\n",
        "    img = load_img(img_path, target_size=IMG_SIZE)\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    feat = base_model.predict(img, verbose=0)\n",
        "    return feat.flatten()\n",
        "\n",
        "def extract_dataset_features(root_dir):\n",
        "    features = []\n",
        "    labels = []\n",
        "    classes = sorted(os.listdir(root_dir))\n",
        "\n",
        "    for cls in classes:\n",
        "        cls_path = os.path.join(root_dir, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "        print(f\"Processing class: {cls}\")\n",
        "\n",
        "        for img_name in tqdm(os.listdir(cls_path)):\n",
        "            img_path = os.path.join(cls_path, img_name)\n",
        "            feat = extract_feature(img_path)\n",
        "#============================================pict to vector feature arr data\n",
        "            features.append(feat)\n",
        "            labels.append(cls)\n",
        "\n",
        "    return np.array(features), np.array(labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWgCy3_ttM2-",
        "outputId": "9ac3d536-969f-41fb-f542-13571b2b5636"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4192577900.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = extract_dataset_features(train_dir)\n",
        "x_val, y_val = extract_dataset_features(val_dir)\n",
        "\n",
        "#============================================endocode classes ke int arr\n",
        "encoder = LabelEncoder()\n",
        "y_train_enc = encoder.fit_transform(y_train)\n",
        "y_val_enc   = encoder.transform(y_val)\n",
        "\n",
        "#============================================sv as npy disk files\n",
        "np.save(\"x_train.npy\", x_train)\n",
        "np.save(\"x_val.npy\", x_val)\n",
        "np.save(\"y_train.npy\", y_train_enc)\n",
        "np.save(\"y_val.npy\", y_val_enc)\n",
        "\n",
        "#============================================sving pkl label encoder\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoder, f)\n",
        "\n",
        "print(\"Saved all features!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQpa743EuFbv",
        "outputId": "ac7ad125-c7a3-4804-81d0-44ded3d6fc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Bacterial_spot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [04:08<00:00,  4.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Early_blight\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:18<00:00,  5.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Late_blight\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:11<00:00,  5.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Leaf_Mold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [02:49<00:00,  5.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Septoria_leaf_spot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:09<00:00,  5.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Spider_mites Two-spotted_spider_mite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:29<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Target_Spot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:54<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:56<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Tomato_mosaic_virus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:13<00:00,  5.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___healthy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:41<00:00,  4.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Bacterial_spot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Early_blight\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Late_blight\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Leaf_Mold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:19<00:00,  5.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Septoria_leaf_spot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Spider_mites Two-spotted_spider_mite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:26<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Target_Spot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___Tomato_mosaic_virus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:19<00:00,  5.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Tomato___healthy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved all features!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#============================================sving pls n npy ke drive (bubble atas biar one run)\n",
        "np.save(\"/content/drive/MyDrive/dataset FP ML/x_train.npy\", x_train)\n",
        "np.save(\"/content/drive/MyDrive/dataset FP ML/x_val.npy\", x_val)\n",
        "np.save(\"/content/drive/MyDrive/dataset FP ML/y_train.npy\", y_train_enc)\n",
        "np.save(\"/content/drive/MyDrive/dataset FP ML/y_val.npy\", y_val_enc)\n",
        "with open(\"/content/drive/MyDrive/dataset FP ML/label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoder, f)"
      ],
      "metadata": {
        "id": "ImorkDCObzQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ac2d2d78-4a6e-4f7e-a338-b4a2aed568d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2570589490.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#============================================sving pls n npy ke drive (bubble atas biar one run)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset FP ML/x_train.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset FP ML/x_val.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset FP ML/y_train.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset FP ML/y_val.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#============================================baseline: DecisionTree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "#============================================path to drive\n",
        "base_path = \"/content/drive/MyDrive/dataset FP ML/\"\n",
        "\n",
        "#============================================reload data\n",
        "x_train = np.load(base_path + \"x_train.npy\")\n",
        "x_val   = np.load(base_path + \"x_val.npy\")\n",
        "y_train = np.load(base_path + \"y_train.npy\")\n",
        "y_val   = np.load(base_path + \"y_val.npy\")\n",
        "\n",
        "#============================================baseline model\n",
        "model = DecisionTreeClassifier(max_depth=None, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_val)\n",
        "\n",
        "#============================================eval predict\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(\"\\nKlasifikasi:\\n\", classification_report(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD--ygSsYUmb",
        "outputId": "cf57588b-eaf8-4d46-e84f-da0855fa777b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.509\n",
            "\n",
            "Klasifikasi:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.55      0.60       100\n",
            "           1       0.36      0.39      0.37       100\n",
            "           2       0.52      0.62      0.56       100\n",
            "           3       0.44      0.46      0.45       100\n",
            "           4       0.41      0.41      0.41       100\n",
            "           5       0.47      0.47      0.47       100\n",
            "           6       0.43      0.41      0.42       100\n",
            "           7       0.76      0.64      0.70       100\n",
            "           8       0.48      0.59      0.53       100\n",
            "           9       0.69      0.55      0.61       100\n",
            "\n",
            "    accuracy                           0.51      1000\n",
            "   macro avg       0.52      0.51      0.51      1000\n",
            "weighted avg       0.52      0.51      0.51      1000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[55  8  4  4  9  5  6  4  4  1]\n",
            " [ 4 39 13 13 10  6  4  3  6  2]\n",
            " [ 2 13 62  3  7  4  1  3  2  3]\n",
            " [ 4  8  8 46  7  5  3  2 16  1]\n",
            " [ 6 12 16  7 41  4  6  1  7  0]\n",
            " [ 0  6  1  7  3 47 12  3 16  5]\n",
            " [ 3  9  7  3  5 14 41  1  8  9]\n",
            " [ 7  5  4  8  4  3  2 64  2  1]\n",
            " [ 1  3  4 12 11  3  2  2 59  3]\n",
            " [ 1  6  1  1  4  9 19  1  3 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#xgboost gpu install, train xgb basic, save for streamlit\n",
        "\n",
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "model_xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    tree_method=\"hist\",   #kalau GPU Colab aktif\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Training XGBoost...\")\n",
        "model_xgb.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model_xgb.predict(x_val)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
        "\n",
        "model_xgb.save_model(base_path + \"xgb_model.json\") #bt streamlit sm pkl sebelumnya"
      ],
      "metadata": {
        "id": "Wlt_262-hPzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d76982-bc81-4fdb-c02a-5c90bb735004"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Training XGBoost...\n",
            "Accuracy: 0.843\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89       100\n",
            "           1       0.81      0.64      0.72       100\n",
            "           2       0.79      0.90      0.84       100\n",
            "           3       0.83      0.88      0.85       100\n",
            "           4       0.85      0.79      0.82       100\n",
            "           5       0.79      0.81      0.80       100\n",
            "           6       0.79      0.74      0.76       100\n",
            "           7       0.95      0.94      0.94       100\n",
            "           8       0.83      0.93      0.88       100\n",
            "           9       0.94      0.88      0.91       100\n",
            "\n",
            "    accuracy                           0.84      1000\n",
            "   macro avg       0.84      0.84      0.84      1000\n",
            "weighted avg       0.84      0.84      0.84      1000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[92  2  0  1  2  1  0  2  0  0]\n",
            " [ 2 64 15  4  4  3  4  0  4  0]\n",
            " [ 0  8 90  2  0  0  0  0  0  0]\n",
            " [ 1  0  2 88  0  3  2  0  4  0]\n",
            " [ 5  3  4  5 79  0  3  0  0  1]\n",
            " [ 0  0  0  6  0 81  4  3  4  2]\n",
            " [ 3  2  1  0  1 12 74  0  4  3]\n",
            " [ 3  0  0  0  0  2  0 94  1  0]\n",
            " [ 0  0  0  0  7  0  0  0 93  0]\n",
            " [ 0  0  2  0  0  1  7  0  2 88]]\n"
          ]
        }
      ]
    }
  ]
}